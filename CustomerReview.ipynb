{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBIisBM2oheD",
        "outputId": "2967a284-e32f-4725-e36e-9e912da65915"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           Complaint  Category Sentiment\n",
            "0           I was overcharged on my bill this month.   Billing   Neutral\n",
            "1  The product I received was defective and damaged.   Product   Neutral\n",
            "2             The delivery was delayed by two weeks.  Delivery   Neutral\n",
            "3      Customer service did not respond to my query.   Service   Neutral\n",
            "4             The quality of the item was excellent!   Product  Positive\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from textblob import TextBlob\n",
        "import pandas as pd\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Define keywords for categories\n",
        "CATEGORY_KEYWORDS = {\n",
        "    \"Billing\": [\"bill\", \"charge\", \"payment\", \"fee\", \"invoice\"],\n",
        "    \"Product\": [\"product\", \"item\", \"quality\", \"defect\", \"damage\"],\n",
        "    \"Service\": [\"service\", \"support\", \"help\", \"delay\", \"response\"],\n",
        "    \"Delivery\": [\"delivery\", \"shipping\", \"late\", \"delay\", \"courier\"],\n",
        "}\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_text(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "    return filtered_tokens\n",
        "\n",
        "# Keyword-based classification\n",
        "def classify_by_keywords(text):\n",
        "    tokens = preprocess_text(text)\n",
        "    category_counts = {category: 0 for category in CATEGORY_KEYWORDS}\n",
        "\n",
        "    for category, keywords in CATEGORY_KEYWORDS.items():\n",
        "        for token in tokens:\n",
        "            if token in keywords:\n",
        "                category_counts[category] += 1\n",
        "\n",
        "    # Determine the category with the highest count\n",
        "    category = max(category_counts, key=category_counts.get)\n",
        "    return category if category_counts[category] > 0 else \"Uncategorized\"\n",
        "\n",
        "# Sentiment analysis\n",
        "def analyze_sentiment(text):\n",
        "    analysis = TextBlob(text)\n",
        "    sentiment_score = analysis.sentiment.polarity\n",
        "\n",
        "    if sentiment_score > 0:\n",
        "        return \"Positive\"\n",
        "    elif sentiment_score < 0:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "# Classify complaints\n",
        "def classify_complaints(data):\n",
        "    results = []\n",
        "\n",
        "    for complaint in data:\n",
        "        category = classify_by_keywords(complaint)\n",
        "        sentiment = analyze_sentiment(complaint)\n",
        "        results.append({\"Complaint\": complaint, \"Category\": category, \"Sentiment\": sentiment})\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    complaints = [\n",
        "        \"I was overcharged on my bill this month.\",\n",
        "        \"The product I received was defective and damaged.\",\n",
        "        \"The delivery was delayed by two weeks.\",\n",
        "        \"Customer service did not respond to my query.\",\n",
        "        \"The quality of the item was excellent!\",\n",
        "    ]\n",
        "\n",
        "    classified_complaints = classify_complaints(complaints)\n",
        "    print(classified_complaints)\n"
      ]
    }
  ]
}